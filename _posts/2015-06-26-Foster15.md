---
title: Variable Selection is Hard
abstract: Variable selection for sparse linear regression is the problem of finding,
  given an m\times p  matrix B and a target vector \bfy,  a sparse vector \bfx such
  that B\bfx approximately equals \bfy. Assuming a standard complexity hypothesis,
  we show that no polynomial-time algorithm can find a k’-sparse \bfx with \|B\bfx-\bfy\|^2\le
  h(m,p), where k’=k⋅2^\log ^1-δ p and h(m,p)= p^C_1 m^1-C_2, where δ>0,C_1>0,C_2>0
  are arbitrary. This is true even under the promise that there is an unknown k-sparse
  vector \bfx^* satisfying B\bfx^*=\bfy. We prove a similar result for a statistical
  version of the problem in which the data are corrupted by noise. To the authors’
  knowledge, these are the first hardness results for sparse regression that apply
  when the algorithm simultaneously has k’>k and h(m,p)>0.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Foster15
month: 0
tex_title: Variable Selection is Hard
firstpage: 696
lastpage: 709
page: 696-709
order: 696
cycles: false
author:
- given: Dean
  family: Foster
- given: Howard
  family: Karloff
- given: Justin
  family: Thaler
date: 2015-06-26
address: Paris, France
publisher: PMLR
container-title: Proceedings of The 28th Conference on Learning Theory
volume: '40'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 26
pdf: http://proceedings.mlr.press/v40/Foster15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
