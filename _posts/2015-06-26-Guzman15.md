---
title: 'Open Problem: The Oracle Complexity of Smooth Convex Optimization in Nonstandard
  Settings'
abstract: First-order convex minimization algorithms are currently the methods of
  choice for large-scale sparse – and more generally parsimonious – regression models.
  We pose the question on the limits of performance of black-box oriented methods
  for convex minimization in \em non-standard settings, where the regularity of the
  objective is measured in a norm not necessarily induced by the feasible domain.
  This question is studied for \ell_p/\ell_q-settings, and their matrix analogues
  (Schatten norms), where we find surprising gaps on lower bounds compared to state
  of the art methods. We propose a conjecture on the optimal convergence rates for
  these settings, for which a positive answer would lead to significant improvements
  on minimization algorithms for parsimonious regression models.
section: open
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Guzman15
month: 0
firstpage: 1761
lastpage: 1763
page: 1761-1763
sections: 
author:
- given: Cristóbal
  family: Guzmán
date: 2015-06-26
address: Paris, France
publisher: PMLR
container-title: Proceedings of The 28th Conference on Learning Theory
volume: '40'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 26
pdf: http://proceedings.mlr.press/v40/Guzman15/Guzman15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
