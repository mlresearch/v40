---
title: 'Learning with Square Loss: Localization through Offset Rademacher Complexity'
abstract: We consider regression with square loss and general classes of functions
  without the boundedness assumption. We introduce a notion of offset Rademacher complexity
  that provides a transparent way to study localization both in expectation and in
  high probability. For any (possibly non-convex) class, the excess loss of a two-step
  estimator is shown to be upper bounded by this offset complexity through a novel
  geometric inequality. In the convex case, the estimator reduces to an empirical
  risk minimizer. The method recovers the results of \citepRakSriTsy15 for the bounded
  case while also providing guarantees without the boundedness assumption.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Liang15
month: 0
tex_title: 'Learning with Square Loss: Localization through Offset Rademacher Complexity'
firstpage: 1260
lastpage: 1285
page: 1260-1285
order: 1260
cycles: false
author:
- given: Tengyuan
  family: Liang
- given: Alexander
  family: Rakhlin
- given: Karthik
  family: Sridharan
date: 2015-06-26
address: Paris, France
publisher: PMLR
container-title: Proceedings of The 28th Conference on Learning Theory
volume: '40'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 26
pdf: http://proceedings.mlr.press/v40/Liang15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
