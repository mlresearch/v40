---
title: On the Complexity of Bandit Linear Optimization
abstract: We study the attainable regret for online linear optimization problems with
  bandit feedback, where unlike the full-information setting, the player can only
  observe its own loss rather than the full loss vector. We show that the price of
  bandit information in this setting can be as large as d, disproving the well-known
  conjecture (Danie et al. (2007)) that the regret for bandit linear optimization
  is at most \sqrtd times the full-information regret. Surprisingly, this is shown
  using “trivial” modifications of standard domains, which have no effect in the full-information
  setting. This and other results we present highlight some interesting differences
  between full-information and bandit learning, which were not considered in previous
  literature.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Shamir15
month: 0
tex_title: On the Complexity of Bandit Linear Optimization
firstpage: 1523
lastpage: 1551
page: 1523-1551
order: 1523
cycles: false
author:
- given: Ohad
  family: Shamir
date: 2015-06-26
address: Paris, France
publisher: PMLR
container-title: Proceedings of The 28th Conference on Learning Theory
volume: '40'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 26
pdf: http://proceedings.mlr.press/v40/Shamir15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
