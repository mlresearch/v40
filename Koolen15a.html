<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Second-order Quantile Methods for Experts and Combinatorial Games | COLT 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Second-order Quantile Methods for Experts and Combinatorial Games">

  <meta name="citation_author" content="Koolen, Wouter M.">

  <meta name="citation_author" content="Van Erven, Tim">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 28th Conference on Learning Theory">
<meta name="citation_firstpage" content="1155">
<meta name="citation_lastpage" content="1175">
<meta name="citation_pdf_url" content="Koolen15a.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Second-order Quantile Methods for Experts and Combinatorial Games</h1>

	<div id="authors">
	
		Wouter M. Koolen,
	
		Tim Van Erven
	<br />
	</div>
	<div id="info">
		Proceedings of The 28th Conference on Learning Theory,
		pp. 1155–1175, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		<p>We aim to design strategies for sequential decision making that adjust to the difficulty of the learning problem. We study this question both in the setting of prediction with expert advice, and for more general combinatorial decision tasks. We are not satisfied with just guaranteeing minimax regret rates, but we want our algorithms to perform significantly better on easy data. Two popular ways to formalize such adaptivity are second-order regret bounds and quantile bounds. The underlying notions of ‘easy data’, which may be paraphrased as “the learning problem has small variance” and “multiple decisions are useful”, are synergetic. But even though there are sophisticated algorithms that exploit one of the two, no existing algorithm is able to adapt to both.</p>
<p>The difficulty in combining the two notions lies in tuning a parameter called the learning rate, whose optimal value behaves non-monotonically. We introduce a potential function for which (very surprisingly!) it is sufficient to simply put a prior on learning rates; an approach that does not work for any previous method. By choosing the right prior we construct efficient algorithms and show that they reap both benefits by proving the first bounds that are both second-order and incorporate quantiles.</p>
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="Koolen15a.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
