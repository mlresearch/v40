<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Sequential Information Maximization: When is Greedy Near-optimal? | COLT 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Sequential Information Maximization: When is Greedy
Near-optimal?">

  <meta name="citation_author" content="Chen, Yuxin">

  <meta name="citation_author" content="Hassani, S. Hamed,">

  <meta name="citation_author" content="Karbasi, Amin">

  <meta name="citation_author" content="Krause, Andreas">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 28th Conference on Learning Theory">
<meta name="citation_firstpage" content="338">
<meta name="citation_lastpage" content="363">
<meta name="citation_pdf_url" content="Chen15b.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Sequential Information Maximization: When is Greedy Near-optimal?</h1>

	<div id="authors">
	
		Yuxin Chen,
	
		S. Hamed, Hassani,
	
		Amin Karbasi,
	
		Andreas Krause
	<br />
	</div>
	<div id="info">
		Proceedings of The 28th Conference on Learning Theory,
		pp. 338–363, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Optimal information gathering is a central challenge in machine learning and science in general. A common objective that quantifies the usefulness of observations is Shannon’s mutual information, defined w.r.t. a probabilistic model. Greedily selecting observations that maximize the mutual information is the method of choice in numerous applications, ranging from Bayesian experimental design to automated diagnosis, to active learning in Bayesian models. Despite its importance and widespread use in applications, little is known about the theoretical properties of sequential information maximization, in particular under noisy observations. In this paper, we analyze the widely used greedy policy for this task, and identify problem instances where it provides provably near-maximal utility, even in the challenging setting of persistent noise. Our results depend on a natural separability condition associated with a channel injecting noise into the observations. We also identify examples where this separability parameter is necessary in the bound: if it is too small, then the greedy policy fails to select informative tests.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="Chen15b.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
