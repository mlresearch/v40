---
title: On Learning Distributions from their Samples
abstract: 'One of the most natural and important questions in statistical learning
  is: how well can a distribution be approximated from its samples. Surprisingly,
  this question has so far been resolved for only one loss, the KL-divergence and
  even in this case, the estimator used is ad hoc and not well understood. We study
  distribution approximations for general loss measures.  For \ell_2^2 we determine
  the best approximation possible, for \ell_1 and Ï‡^2 we derive tight bounds on the
  best approximation, and when the probabilities are bounded away from zero, we resolve
  the question for all sufficiently smooth loss measures, thereby providing a coherent
  understanding of the rate at which distributions can be approximated from their
  samples.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Kamath15
month: 0
tex_title: On Learning Distributions from their Samples
firstpage: 1066
lastpage: 1100
page: 1066-1100
sections: 
author:
- given: Sudeep
  family: Kamath
- given: Alon
  family: Orlitsky
- given: Dheeraj
  family: Pichapati
- given: Ananda Theertha
  family: Suresh
date: 2015-06-26
address: Paris, France
publisher: PMLR
container-title: Proceedings of The 28th Conference on Learning Theory
volume: '40'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 26
pdf: http://proceedings.mlr.press/v40/Kamath15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
