<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Convex Risk Minimization and Conditional Probability Estimation | COLT 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Convex Risk Minimization and Conditional Probability Estimation">

  <meta name="citation_author" content="Telgarsky, Matus">

  <meta name="citation_author" content="Dud&lt;span&gt;í&lt;/span&gt;k, Miroslav">

  <meta name="citation_author" content="Schapire, Robert">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 28th Conference on Learning Theory">
<meta name="citation_firstpage" content="1629">
<meta name="citation_lastpage" content="1682">
<meta name="citation_pdf_url" content="Telgarsky15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Convex Risk Minimization and Conditional Probability Estimation</h1>

	<div id="authors">
	
		Matus Telgarsky,
	
		Miroslav Dud<span>í</span>k,
	
		Robert Schapire
	<br />
	</div>
	<div id="info">
		Proceedings of The 28th Conference on Learning Theory,
		pp. 1629–1682, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		This paper proves, in very general settings, that convex risk minimization is a procedure to select a unique conditional probability model determined by the classification problem. Unlike most previous work, we give results that are general enough to include cases in which no minimum exists, as occurs typically, for instance, with standard boosting algorithms. Concretely, we first show that any sequence of predictors minimizing convex risk over the source distribution will converge to this unique model when the class of predictors is linear (but potentially of infinite dimension). Secondly, we show the same result holds for <em>empirical</em> risk minimization whenever this class of predictors is finite dimensional, where the essential technical contribution is a norm-free generalization bound.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="Telgarsky15.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
